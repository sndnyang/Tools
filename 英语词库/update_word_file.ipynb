{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import xlrd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def needEscape(l):\n",
    "    if l.find(u'人名') > 0:\n",
    "        return True\n",
    "    if l.find(u'货币基本单位') > 0:\n",
    "        return True\n",
    "    if l.find('abbr') > -1:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xls2list(fname):\n",
    "\n",
    "    data = xlrd.open_workbook(fname + '.xls')\n",
    "    table = data.sheets()[0]\n",
    "    nrows = table.nrows # 获取表的行数\n",
    "    l = ['word', 'level', 'lenovo', 'etyma', 'meanZh', 'meanEn', 'example', 'phonetic', 'test']\n",
    "\n",
    "    content = []\n",
    "\n",
    "    for i in range(1, nrows): # 循环逐行打印\n",
    "        if i == 0: # 跳过第一行\n",
    "            continue\n",
    "        row = table.row_values(i)[:len(l)]\n",
    "        if len(row) > len(l):\n",
    "            print len(row), row\n",
    "            sys.exit()\n",
    "        content.append(row)\n",
    "\n",
    "    print len(content)\n",
    "    return content, l\n",
    "\n",
    "def list2df(para):\n",
    "    content, l = para\n",
    "    data = pd.DataFrame(content, columns=l)\n",
    "\n",
    "    data['selfLenovo'] = \"\"\n",
    "    data['level'] = 0\n",
    "    return data\n",
    "\n",
    "def gloss2test(data):\n",
    "\n",
    "    test = {'CET4':'四级', 'CET6':'六级', 'TOEFL':'托福', \n",
    "            'GRE':'GRE', 'GRE3000':'GRE-再要你命3000', \n",
    "            'GREmagoosh':'GRE-Magoosh'}\n",
    "\n",
    "    f = file(\"books.txt\", \"w\")\n",
    "\n",
    "    for t in test:\n",
    "        subset = data[data['test'].str.contains(t)]\n",
    "        con  = sq.connect(t.lower() + '.db')\n",
    "        subset[subset.columns[:-1]].to_sql('word', con)\n",
    "        con.close()\n",
    "\n",
    "        m = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime(os.path.getmtime('gloss.xls')))\n",
    "        s = \"%s http://7xt8es.com1.z0.glb.clouddn.com/naodong/word/%s.db %d(%s更新)\" % (test[t], t.lower(), len(subset), m)\n",
    "\n",
    "        f.write(s)\n",
    "\n",
    "        f.write('\\n')\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return len(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19211\n"
     ]
    }
   ],
   "source": [
    "data = list2df(xls2list('gloss2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[(data['phonetic'] == '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"'\\xe6bd\\u0292ektli\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = YoudaoSpider('abjectly')\n",
    "sample = test.get_result()\n",
    "result = transform(sample)\n",
    "printDeep(result, 2)\n",
    "result['phonetic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import webbrowser\n",
    "#from termcolor import colored\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "def printDeep(item, deep):\n",
    "    if isinstance(item, (str, bool, int, float)):\n",
    "        print ' '*deep, item\n",
    "    elif isinstance(item, (list, tuple)):\n",
    "        print ' '*deep, 'a list'\n",
    "        for e in item:\n",
    "            if isinstance(e, (str, bool, int, float, unicode)):\n",
    "                print ' '*(deep+4), e\n",
    "            else:\n",
    "                printDeep(e, deep+4)\n",
    "    elif isinstance(item, dict):\n",
    "        print ' '*deep, 'a dict'\n",
    "        for e in item:\n",
    "            print ' '*(deep+4), e, ':', item[e]\n",
    "            if not isinstance(item[e], (str, bool, int, float)):\n",
    "                printDeep(item[e], deep+4)\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "def addBilingual(example):\n",
    "    bilingual = example.find(id='bilingual')\n",
    "    if not bilingual:\n",
    "        return None\n",
    "    ul = bilingual.find_all('li')\n",
    "    b = []\n",
    "    for l in ul:\n",
    "        t = l.find_all('p')\n",
    "        en = ''.join(e.string if e.string else e.text for e in t[0].find_all('span'))\n",
    "        zh = ''.join(e.string if e.string else e.text for e in t[1].find_all('span'))\n",
    "        b.append(zh + ':' + en)\n",
    "    return b\n",
    "\n",
    "\n",
    "# In[75]:\n",
    "\n",
    "def addExample(example, name):\n",
    "    items = example.find(id=name)\n",
    "    if not items:\n",
    "        return None\n",
    "    ul = items.find_all('li')\n",
    "    b = []\n",
    "    for l in ul:\n",
    "        en = l.find('p').text\n",
    "        b.append(':' + en.strip())\n",
    "    return b\n",
    "\n",
    "\n",
    "# In[91]:\n",
    "\n",
    "\n",
    "class YoudaoSpider:\n",
    "    \"\"\"\n",
    "    通过有道获取单词解释, 以及展示查询结果\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        'keyfrom': 'longcwang',\n",
    "        'key': '131895274',\n",
    "        'type': 'data',\n",
    "        'doctype': 'json',\n",
    "        'version': '1.1',\n",
    "        'q': 'query'\n",
    "    }\n",
    "    api_url = u'http://fanyi.youdao.com/openapi.do'\n",
    "    voice_url = u'http://dict.youdao.com/dictvoice?type=2&audio={word}'\n",
    "    web_url = u'http://dict.youdao.com/search?keyfrom=dict.top&q='\n",
    "    translation_url = u'http://fanyi.youdao.com/translate?keyfrom=dict.top&i='\n",
    "\n",
    "    error_code = {\n",
    "        0: u'正常',\n",
    "        20: u'要翻译的文本过长',\n",
    "        30: u'无法进行有效的翻译',\n",
    "        40: u'不支持的语言类型',\n",
    "        50: u'无效的key',\n",
    "        60: u'无词典结果，仅在获取词典结果生效'\n",
    "    }\n",
    "\n",
    "    result = {\n",
    "        \"query\": \"\",\n",
    "        \"errorCode\": 0,\n",
    "    }\n",
    "\n",
    "    def __init__(self, word):\n",
    "        self.word = word\n",
    "\n",
    "    def get_result(self, use_api=False):\n",
    "        \"\"\"\n",
    "        获取查询结果\n",
    "        :param use_api:是否使用有道API, 否则解析web版有道获取结果\n",
    "        :return:与有道API返回的json数据一致的dict\n",
    "        \"\"\"\n",
    "        if use_api:\n",
    "            self.params['q'] = self.word\n",
    "            r = requests.get(self.api_url, params=self.params)\n",
    "            r.raise_for_status()    # a 4XX client error or 5XX server error response\n",
    "            self.result = r.json()\n",
    "        else:\n",
    "            r = requests.get(self.web_url + self.word)\n",
    "            r.raise_for_status()\n",
    "            self.parse_html(r.text)\n",
    "        return self.result\n",
    "\n",
    "    def parse_html(self, html):\n",
    "        \"\"\"\n",
    "        解析web版有道的网页\n",
    "        :param html:网页内容\n",
    "        :return:result\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        root = soup.find(id='results-contents')\n",
    "        \n",
    "        if not root:\n",
    "            self.result = {'query': '', 'example': '', 'basic':{'explains':''}}\n",
    "            return\n",
    "\n",
    "        # query 搜索的关键字\n",
    "        keyword = root.find(class_='keyword')\n",
    "        if not keyword:\n",
    "            self.result['query'] = self.word\n",
    "        else:\n",
    "            self.result['query'] = unicode(keyword.string)\n",
    "\n",
    "        # 基本解释\n",
    "        basic = root.find(id='phrsListTab')\n",
    "        if basic:\n",
    "            trans = basic.find(class_='trans-container')\n",
    "            if trans:\n",
    "                self.result['basic'] = {}\n",
    "                self.result['basic']['explains'] = [unicode(tran.string) for tran in trans.find_all('li')]\n",
    "                # 中文\n",
    "                if len(self.result['basic']['explains']) == 0:\n",
    "                    exp = trans.find(class_='wordGroup').stripped_strings\n",
    "                    self.result['basic']['explains'].append(' '.join(exp))\n",
    "\n",
    "                # 音标\n",
    "                phons = basic(class_='phonetic', limit=2)\n",
    "                if len(phons) == 2:\n",
    "                    self.result['basic']['uk-phonetic'], self.result['basic']['us-phonetic'] =                         [unicode(p.string)[1:-1] for p in phons]\n",
    "                elif len(phons) == 1:\n",
    "                    self.result['basic']['phonetic'] = unicode(phons[0].string)[1:-1]\n",
    "        # 英文译义\n",
    "        # meanEn = root.find(id='tEETrans')\n",
    "        # 翻译\n",
    "        if 'basic' not in self.result:\n",
    "            self.result['translation'] = self.get_translation(self.word)\n",
    "\n",
    "        # 网络释义(短语)\n",
    "        web = root.find(id='webPhrase')\n",
    "        if web:\n",
    "            self.result['web'] = [\n",
    "                {\n",
    "                    'key': unicode(wordgroup.find(class_='search-js').string).strip(),\n",
    "                    'value': [v.strip() for v in unicode(wordgroup.find('span').next_sibling).split(';')]\n",
    "                } for wordgroup in web.find_all(class_='wordGroup', limit=4)\n",
    "            ]\n",
    "            \n",
    "        example = root.find(id='examplesToggle')\n",
    "        self.result['example'] = []\n",
    "        if not example:\n",
    "            return\n",
    "        \n",
    "        bi = addBilingual(example)\n",
    "\n",
    "        if bi:\n",
    "            self.result['example'] += bi\n",
    "        other = addExample(example, 'originalSound')\n",
    "        if other:\n",
    "            self.result['example'] += other\n",
    "        other = addExample(example, 'authority')\n",
    "        if other:\n",
    "            self.result['example'] += other        \n",
    "\n",
    "    def get_translation(self, word):\n",
    "        \"\"\"\n",
    "        通过web版有道翻译抓取翻译结果\n",
    "        :param word:str 关键字\n",
    "        :return:list 翻译结果\n",
    "        \"\"\"\n",
    "        r = requests.get(self.translation_url+word)\n",
    "        if r.status_code != requests.codes.ok:\n",
    "            return None\n",
    "\n",
    "        pattern = re.compile(r'\"translateResult\":\\[(\\[.+\\])\\]')\n",
    "        m = pattern.search(r.text)\n",
    "        result = json.loads(m.group(1))\n",
    "        return [item['tgt'] for item in result]\n",
    "\n",
    "    @classmethod\n",
    "    def get_voice(cls, word):\n",
    "        voice_file = os.path.join(VOICE_DIR, word+'.mp3')\n",
    "        if not os.path.isfile(voice_file):\n",
    "            r = requests.get(cls.voice_url.format(word=word))\n",
    "            with open(voice_file, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        return voice_file\n",
    "\n",
    "\n",
    "# In[103]:\n",
    "\n",
    "# word\tlevel\tlenovo\tetyma\tmeanZh\tmeanEn\texample\tphonetic\n",
    "def transform(sample):\n",
    "    result = {'word': sample['query'], 'example': '\\n'.join(sample['example']),\n",
    "             'meanZh': '\\n'.join(sample['basic']['explains'])}\n",
    "    if 'phonetic' in sample['basic']:\n",
    "        result['phonetic'] = sample['basic']['phonetic']\n",
    "    elif 'uk-phonetic' in sample['basic'] and 'us-phonetic' in sample['basic']:\n",
    "        result['phonetic'] = u'英:[' + sample['basic']['uk-phonetic'] + u'] 美:[' +            sample['basic']['uk-phonetic'] + u']'\n",
    "    return result\n",
    "\n",
    "\n",
    "# In[105]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo = YoudaoSpider('create')\n",
    "sample = demo.get_result()\n",
    "result = transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def crawl(x):\n",
    "    global c\n",
    "    c += 1\n",
    "    print c\n",
    "    demo = YoudaoSpider(x[0])\n",
    "    sample = demo.get_result()\n",
    "    result = transform(sample)\n",
    "\n",
    "    return result['example'] if 'example' in result else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     鍦ㄨ嫳璇�噷鎴戜滑鍙�畠涓轰竴涓�畻鐩樸�:In English we call it an abacus...\n",
       "10    鍦�娓呭崟 1涓�垜澶ч噺浣跨敤浜嗘�缂╁啓銆�I used this abbreviation hea...\n",
       "13    鎵�弿浠栫殑鑳搁儴锛岃吂閮ㄥ拰楠ㄧ泦涔熸病鏈変粈涔堝彂鐜般�:Scans of his chest, abdom...\n",
       "23    鎴戜笉鑳藉�蹇嶆�楠�:I can't abide dishonesty!\\n浣犳�鑳藉�蹇嶄粬?:Ho...\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "data[data['example'] == ''][:4].apply(crawl, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data['phonetic'].str[0] == '/', 'phonetic'] = data[data['phonetic'].str[0] == '/'].apply(crawl, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['phonetic'].str[0] == '/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['phonetic'].str[0] == '/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data[(data['example'] == '')]\n",
    "data.loc[data['example'] == '', 'example'] = data[data['example'] == ''].apply(crawl, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[(data['example'] == '')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CET4 4510\n",
      "TOFEL 2081\n",
      "CET6 11171\n",
      "GRE3000 3060\n",
      "GRE 7972\n",
      "GREmagoosh 1010\n"
     ]
    }
   ],
   "source": [
    "test = {'CET4':'四级', 'CET6':'六级', 'TOFEL':'托福', \n",
    "            'GRE':'GRE', 'GRE3000':'GRE-再要你命3000', \n",
    "            'GREmagoosh':'GRE-Magoosh'}\n",
    "\n",
    "for t in test:\n",
    "    if t == 'CET6':\n",
    "        subset = data[(data['test'].str.contains(t))&(~data['test'].str.contains('CET4'))]\n",
    "    else:\n",
    "        subset = data[(data['test'].str.contains(t))]\n",
    "    print t, len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010\n"
     ]
    }
   ],
   "source": [
    "t = data[data['test'].str.contains('GREmagoosh')]\n",
    "print len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719\n"
     ]
    }
   ],
   "source": [
    "a = data[data['test'].str.contains('GRE3000')]\n",
    "print len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3094\n"
     ]
    }
   ],
   "source": [
    "p = list2df(xls2list('another-3000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tw = set(t['word'])\n",
    "pw = set(p['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tw.intersection(pw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2480\n"
     ]
    }
   ],
   "source": [
    "d = pw.difference(tw)\n",
    "print len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data['word'].isin(d), 'test'] += ' GRE3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'word', u'level', u'lenovo', u'etyma', u'meanZh', u'meanEn',\n",
       "       u'example', u'phonetic', u'test'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19211"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[data['word'].isin(d), 'word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('gloss4.xls')\n",
    "data.to_excel(writer, index = False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['word'].isin(d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19211"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[:, 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_chinese(uchar):\n",
    "    \"\"\"判断一个unicode是否是汉字\"\"\"\n",
    "    if uchar >= u'\\u4e00' and uchar<=u'\\u9fa5':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = u\"中\"\n",
    "is_chinese(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '123132354523'\n",
    "x.find('12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjustExample(x):\n",
    "    lines = x.strip().split('\\n')\n",
    "    result = []\n",
    "    for l in lines:\n",
    "        if l.find('||') > -1:\n",
    "            result.append(l)\n",
    "            continue\n",
    "            \n",
    "        parts = l.split(':')\n",
    "        \n",
    "        if len(parts) == 1:\n",
    "            continue\n",
    "        if len(parts) > 2:\n",
    "            c = ':'.join(parts[1:]).strip()\n",
    "        else:\n",
    "            c = parts[1].strip()\n",
    "        words = c.split()\n",
    "        p = len(words)\n",
    "        for w in words:\n",
    "            if is_chinese(w[0]):\n",
    "                p = words.index(w)\n",
    "                break\n",
    "            \n",
    "        sentence_en = ' '.join(words[:p])\n",
    "        sentence_ch = ' '.join(words[p:])\n",
    "        if not parts[0]:\n",
    "            z = sentence_ch\n",
    "        else:\n",
    "            z = parts[0]\n",
    "            if sentence_ch:\n",
    "                z += '#' + sentence_ch\n",
    "        result.append(z + ':' + sentence_en)\n",
    "    result.sort(key = lambda x:len(x), reverse=True)\n",
    "    return '\\n'.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    :We call it a function. That is to say it has ...\n",
       "1    :Curt Onalfo's playing career included many ap...\n",
       "2    为了改善学生日渐衰退的计算能力，日本的一些学校重新使用起一个古老的计算工具-算盘。:In r...\n",
       "3    v. 放纵#感情用事，abandon herself to a life of comple...\n",
       "4    v. 降低（地位、职位、威望或尊严）#不愿意屈就自己去承认一个莫须有的罪名:was unwi...\n",
       "Name: example, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['example'][:5].apply(adjustExample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[:, 'example'] = data['example'].apply(adjustExample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ['x']\n",
    "':'.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adfsd', 'fsdofksj', 'fsafsd']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'adfsd,fsdofksj;fsafsd'\n",
    "import re\n",
    "re.split('[,;]', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def adjustMeanZh(x):\n",
    "    global c\n",
    "    \n",
    "    if not x[4] or x[4][0] not in string.ascii_letters:\n",
    "        c += 1\n",
    "        print x[0]\n",
    "        #demo = YoudaoSpider(x[4])\n",
    "        #sample = demo.get_result()\n",
    "        #result = transform(sample)\n",
    "        #return result['meanZh']\n",
    "        return ''\n",
    "        \n",
    "    #result = '\\n'.join(l.replace('a.', 'adj.') for l in x[4].strip().split('\\n')\n",
    "    #                   if l and l[0] in string.ascii_letters and l.find('.') > -1 and l.find(u'人名') == -1)    \n",
    "    # result = '\\n'.join(l.replace('a.', 'adj.') for l in x[4].strip().split('\\n') if l.find(u'人名') == -1)    \n",
    "    return x[4]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apocrypha\n",
      "bolted\n",
      "condole  with\n",
      "conduce  to\n",
      "coterminous\n",
      "dainty\n",
      "drabness\n",
      "epistle\n",
      "expostulate\n",
      "gargoyle\n",
      "haemophilia\n",
      "haemostat\n",
      "hauteur\n",
      "hecatomb\n",
      "hors d' oeuvre\n",
      "hot  water\n",
      "imbue  with\n",
      "incipience\n",
      "infallibility\n",
      "jigsaw  puzzle\n",
      "June\n",
      "mercedes\n",
      "misattribute\n",
      "mistimed\n",
      "muniments\n",
      "phillip\n",
      "prometheus\n",
      "purlieus\n",
      "saith\n",
      "snips\n",
      "spleenish\n",
      "sullivan\n",
      "susceptibilities\n",
      "tined\n",
      "unfailing\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "x = data.apply(adjustMeanZh, 1)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19211"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apocrypha\n",
      "bolted\n",
      "condole  with\n",
      "conduce  to\n",
      "coterminous\n",
      "dainty\n",
      "drabness\n",
      "epistle\n",
      "expostulate\n",
      "gargoyle\n",
      "haemophilia\n",
      "haemostat\n",
      "hauteur\n",
      "hecatomb\n",
      "hors d' oeuvre\n",
      "hot  water\n",
      "imbue  with\n",
      "incipience\n",
      "infallibility\n",
      "jigsaw  puzzle\n",
      "June\n",
      "mercedes\n",
      "misattribute\n",
      "mistimed\n",
      "muniments\n",
      "phillip\n",
      "prometheus\n",
      "purlieus\n",
      "saith\n",
      "snips\n",
      "spleenish\n",
      "sullivan\n",
      "susceptibilities\n",
      "tined\n",
      "unfailing\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "data.loc[:, 'meanZh'] = data.apply(adjustMeanZh, 1)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421\n"
     ]
    }
   ],
   "source": [
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-41-37da20cff78f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-41-37da20cff78f>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    x = data[(data['meanZh'] == '')|(~data['meanZh'].str[0] is in string.ascii_letters)]\u001b[0m\n\u001b[1;37m                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "x = data\n",
    "print len(x)\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ".apply(adjustMeanZh, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
